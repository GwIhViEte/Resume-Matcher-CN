#!/usr/bin/env bash
# deploy.sh - èœå•å¼ä¸€é”®éƒ¨ç½²
# é€‚ç”¨ç»“æ„ï¼šæ ¹ package.jsonï¼ˆå¯é€‰ï¼‰ã€apps/backendï¼ˆPython/uvï¼Œå¯é€‰ï¼‰ã€apps/frontendï¼ˆNodeï¼Œå¯é€‰ï¼‰
# ç”Ÿäº§ä¼˜å…ˆ docker composeï¼›æ—  compose åˆ™ä½¿ç”¨ PM2 è¿›è¡ŒæŒä¹…åŒ–ï¼ˆç”Ÿæˆ ecosystem.config.js å¹¶å¼€æœºè‡ªå¯ï¼‰

# ========================= åŸºç¡€è®¾ç½®ä¸ç¨³å®šé”™è¯¯æ•æ‰ =========================
set -Eeuo pipefail
IFS=$'\n\t'
export PYTHONDONTWRITEBYTECODE=1

# DEBUGï¼šDEPLOY_DEBUG=1 ./deploy.sh
if [[ "${DEPLOY_DEBUG:-0}" == "1" ]]; then
  set -x
  export PS4='+[$(date "+%H:%M:%S")] '
fi

# è®© ERR trap ä¹Ÿåœ¨å‡½æ•°/å­è¿›ç¨‹é‡Œç”Ÿæ•ˆï¼›ä»»ä½•å‘½ä»¤å¤±è´¥æ—¶æ‰“å°å…·ä½“å‘½ä»¤ã€é€€å‡ºç ã€æ–‡ä»¶ä¸è¡Œå·
set -o errtrace
trap 'rc=$?; cmd=$BASH_COMMAND; printf "ğŸ’¥ å‘½ä»¤å¤±è´¥ï¼š%q (exit=%d) at %s:%d\n" "$cmd" "$rc" "${BASH_SOURCE[0]}" "${LINENO}"; exit $rc' ERR

# ========================= åŸºæœ¬ä¿¡æ¯ =========================
APP_NAME="resume-matcher-cn"
RUNTIME_DIR=".deploy_runtime"
mkdir -p "$RUNTIME_DIR"

# ========================= è¶…æ—¶/é‡è¯•é…ç½®ï¼ˆé˜²å¡æ­»ï¼‰ =========================
APT_TIMEOUT=600           # apt è¶…æ—¶ï¼ˆç§’ï¼‰
CURL_CONNECT_TIMEOUT=15   # curl è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
CURL_MAX_TIME=180         # curl è¯·æ±‚æ€»ä½“è¶…æ—¶ï¼ˆç§’ï¼‰
NPM_FETCH_TIMEOUT=120000  # npm fetch è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
NPM_FETCH_RETRIES=5
UV_HTTP_TIMEOUT=120       # uv http è¶…æ—¶ï¼ˆç§’ï¼‰
PIP_DEFAULT_TIMEOUT=120   # pip è¶…æ—¶ï¼ˆç§’ï¼‰

# ç»™å­è¿›ç¨‹ç”Ÿæ•ˆï¼ˆå½“å‰ä¼šè¯ï¼‰
export UV_HTTP_TIMEOUT PIP_DEFAULT_TIMEOUT
export NPM_CONFIG_FETCH_TIMEOUT="$NPM_FETCH_TIMEOUT"
export NPM_CONFIG_FETCH_RETRIES="$NPM_FETCH_RETRIES"
export NPM_CONFIG_FETCH_RETRY_FACTOR=2

# ========================= é•œåƒ / ä»£ç† =========================
NPM_REGISTRY_DEFAULT="https://registry.npmmirror.com"
PIP_INDEX_DEFAULT="https://pypi.tuna.tsinghua.edu.cn/simple"
UV_INDEX_DEFAULT="$PIP_INDEX_DEFAULT"
HTTP_PROXY_DEFAULT=""
HTTPS_PROXY_DEFAULT=""

CONF="$RUNTIME_DIR/config.env"
if [[ -f "$CONF" ]]; then
  # shellcheck disable=SC1090
  source "$CONF"
fi

# ========================= å·¥å…·å‡½æ•° =========================
info() { echo -e "â„¹ï¸  $*"; }
ok()   { echo -e "âœ… $*"; }
err()  { echo -e "âŒ $*" >&2; }
have() { command -v "$1" >/dev/null 2>&1; }

persist_conf() {
  cat >"$CONF" <<EOF
NPM_REGISTRY_DEFAULT="${NPM_REGISTRY_DEFAULT}"
PIP_INDEX_DEFAULT="${PIP_INDEX_DEFAULT}"
UV_INDEX_DEFAULT="${UV_INDEX_DEFAULT}"
HTTP_PROXY_DEFAULT="${HTTP_PROXY_DEFAULT}"
HTTPS_PROXY_DEFAULT="${HTTPS_PROXY_DEFAULT}"
EOF
  ok "é…ç½®å·²ä¿å­˜åˆ° $CONF"
}

apply_session_mirrors_and_proxy() {
  export NPM_CONFIG_REGISTRY="${NPM_REGISTRY_DEFAULT}"
  export PIP_INDEX_URL="${PIP_INDEX_DEFAULT}"
  export UV_INDEX_URL="${UV_INDEX_DEFAULT}"
  [[ -n "${HTTP_PROXY_DEFAULT}"  ]] && export HTTP_PROXY="${HTTP_PROXY_DEFAULT}"  && export http_proxy="${HTTP_PROXY_DEFAULT}"
  [[ -n "${HTTPS_PROXY_DEFAULT}" ]] && export HTTPS_PROXY="${HTTPS_PROXY_DEFAULT}" && export https_proxy="${HTTPS_PROXY_DEFAULT}"
  info "ä¼šè¯é•œåƒä¸ä»£ç†ï¼šnpm=$NPM_CONFIG_REGISTRY, pip=$PIP_INDEX_URL, proxy=${HTTP_PROXY_DEFAULT:-none}"
}

# å¸¦è¶…æ—¶ä¸é‡è¯•çš„æ‰§è¡Œå™¨
# ç”¨æ³•ï¼šrun_with_retry "æè¿°" è¶…æ—¶(ç§’) é‡è¯•æ¬¡æ•° -- cmd arg1 ...
run_with_retry() {
  local label="$1"; shift
  local timeout_s="$1"; shift
  local retries="$1"; shift
  echo "â¡ï¸  ${label}ï¼ˆè¶…æ—¶ ${timeout_s}sï¼Œé‡è¯• ${retries} æ¬¡ï¼‰"
  local attempt=1
  while :; do
    if timeout --preserve-status "${timeout_s}" "$@"; then
      echo "âœ… ${label} æˆåŠŸ"
      return 0
    fi
    echo "âš ï¸  ${label} å¤±è´¥ï¼ˆç¬¬ ${attempt} æ¬¡ï¼‰"
    if (( attempt >= retries )); then
      echo "âŒ ${label} é‡è¯•ç”¨å°½"
      return 1
    fi
    attempt=$((attempt+1))
    sleep 2
  done
}

# ========================= ä¾èµ–ä¸å®‰è£… =========================
auto_fix_deps() {
  local need=(bash curl make git python3 pip3 node npm)
  local miss=()
  for b in "${need[@]}"; do have "$b" || miss+=("$b"); done
  if ((${#miss[@]})); then
    info "ç¼ºå¤±ä¾èµ–ï¼š${miss[*]}ï¼Œç”¨ apt å®‰è£…ï¼ˆéœ€ sudoï¼‰"
    export DEBIAN_FRONTEND=noninteractive
    run_with_retry "apt-get update"  "$APT_TIMEOUT" 2 sudo apt-get update -y
    run_with_retry "apt-get install åŸºç¡€å·¥å…·" "$APT_TIMEOUT" 2 sudo apt-get install -y \
      bash curl make git python3 python3-pip nodejs npm coreutils
  fi
  ok "åŸºç¡€ä¾èµ–å°±ç»ª"
}

install_or_update_uv() {
  if have uv; then
    ok "uv å·²å­˜åœ¨ï¼š$(uv --version || true)"
    return 0
  fi
  info "å¼€å§‹å®‰è£… uvï¼ˆé•œåƒå›é€€ + è¶…æ—¶ï¼‰..."
  local urls=(
    "https://mirror.ghproxy.com/https://astral.sh/uv/install.sh"
    "https://ghproxy.com/https://astral.sh/uv/install.sh"
    "https://astral.sh/uv/install.sh"
  )
  local tmp; tmp="$(mktemp)"
  for u in "${urls[@]}"; do
    info "è·å–å®‰è£…è„šæœ¬ï¼š$u"
    if curl -fsSL --connect-timeout "$CURL_CONNECT_TIMEOUT" --max-time "$CURL_MAX_TIME" "$u" -o "$tmp"; then
      sed -i \
        -e 's#https://github.com#https://mirror.ghproxy.com/https://github.com#g' \
        -e 's#https://objects.githubusercontent.com#https://mirror.ghproxy.com/https://objects.githubusercontent.com#g' \
        "$tmp"
      if timeout "$CURL_MAX_TIME" bash "$tmp"; then
        rm -f "$tmp"
        export PATH="$HOME/.local/bin:$PATH"
        ok "uv å®‰è£…å®Œæˆ"
        return 0
      fi
    fi
  done
  err "uv å®‰è£…å¤±è´¥ï¼ˆç½‘ç»œæˆ–ä»£ç†é—®é¢˜ï¼‰"
  return 1
}

install_root_node() {
  if [[ -f package.json ]]; then
    info "å®‰è£…æ ¹ä¾èµ–..."
    if [[ -f package-lock.json ]]; then
      # å…³é”®ï¼šå¿½ç•¥æ ¹ install è„šæœ¬ï¼Œé¿å…è§¦å‘å­é¡¹ç›®äºŒæ¬¡å®‰è£…å¯¼è‡´å¡é¡¿
      run_with_retry "npm ci (root)" 600 2 npm ci --no-fund --no-audit --ignore-scripts
    else
      run_with_retry "npm install (root)" 900 2 npm install --no-fund --no-audit --ignore-scripts
    fi
    ok "æ ¹ä¾èµ–å®‰è£…å®Œæˆ"
  fi
}

install_frontend_node() {
  if [[ -d apps/frontend ]]; then
    info "å®‰è£…å‰ç«¯ä¾èµ–..."
    (
      cd apps/frontend
      if [[ -f package-lock.json ]]; then
        run_with_retry "npm ci (frontend)" 600 2 npm ci --no-fund --no-audit --prefer-offline --progress=false
      else
        run_with_retry "npm install (frontend)" 900 2 npm install --no-fund --no-audit --prefer-offline --progress=false
      fi
    )
    ok "å‰ç«¯ä¾èµ–å®‰è£…å®Œæˆ"
  fi
}

# ---------- PDF è§£æç¯å¢ƒï¼ˆç³»ç»Ÿä¾èµ– + Python ä¾èµ–å…œåº•ï¼‰ ----------
install_pdf_runtime() {
  info "å®‰è£… PDF è§£æç³»ç»Ÿä¾èµ–ï¼ˆpoppler/tesseract/imagemagick/ghostscript/ä¸­æ–‡å­—ä½“ï¼‰..."
  export DEBIAN_FRONTEND=noninteractive
  run_with_retry "apt-get update"  "$APT_TIMEOUT" 2 sudo apt-get update -y
  run_with_retry "apt-get install pdf deps" "$APT_TIMEOUT" 2 sudo apt-get install -y \
    poppler-utils ghostscript imagemagick \
    tesseract-ocr libtesseract-dev tesseract-ocr-chi-sim tesseract-ocr-chi-tra \
    fontconfig fonts-noto-cjk libcairo2 libpango-1.0-0 libxml2
  patch_imagemagick_policy
  ok "ç³»ç»Ÿä¾èµ–å·²å®‰è£…"
}

patch_imagemagick_policy() {
  # ImageMagick åœ¨ä¸å°‘å‘è¡Œç‰ˆé»˜è®¤ç¦ç”¨ PDF/PS è¯»å–ï¼›è¿™é‡Œæ”¹ä¸ºåªè¯»ï¼ˆæ›´å®‰å…¨ï¼‰
  local policy6="/etc/ImageMagick-6/policy.xml"
  local policy7="/etc/ImageMagick-7/policy.xml"
  local edited=false
  for f in "$policy6" "$policy7"; do
    if [[ -f "$f" ]]; then
      sudo cp -a "$f" "${f}.bak" || true
      sudo sed -i \
        -e 's#<policy domain="coder" rights="none" pattern="PDF" />#<policy domain="coder" rights="read" pattern="PDF" />#g' \
        -e 's#<policy domain="coder" rights="none" pattern="PS" />#<policy domain="coder" rights="read" pattern="PS" />#g' \
        -e 's#<policy domain="coder" rights="none" pattern="EPS" />#<policy domain="coder" rights="read" pattern="EPS" />#g' \
        "$f" && edited=true
    fi
  done
  $edited && ok "å·²è°ƒæ•´ ImageMagick policyï¼ˆPDF/PS/EPS å…è®¸åªè¯»ï¼‰" || info "æœªå‘ç°éœ€è¦è°ƒæ•´çš„ ImageMagick policyï¼Œè·³è¿‡"
}

install_backend_py() {
  if [[ -d apps/backend ]]; then
    info "å®‰è£…åç«¯ä¾èµ–..."
    (
      cd apps/backend
      [[ -d .venv ]] || uv venv
      # shellcheck disable=SC1091
      source .venv/bin/activate
      if [[ -f pyproject.toml ]]; then
        if [[ -f uv.lock || -f requirements.txt ]]; then
          run_with_retry "uv sync (backend)" 900 2 uv sync
          if [[ -f requirements.txt ]]; then
            run_with_retry "uv pip install -r requirements.txt (backend)" 900 2 uv pip install -r requirements.txt --index-url "$PIP_INDEX_URL"
          fi
        else
          run_with_retry "uv pip install -e . (backend)" 900 2 uv pip install -e . --index-url "$PIP_INDEX_URL"
        fi
      else
        run_with_retry "uv pip install -e . (backend legacy)" 900 2 uv pip install -e . --index-url "$PIP_INDEX_URL"
      fi
      # å…œåº•ï¼šæ— è®ºé¡¹ç›®å£°æ˜å¦‚ä½•ï¼Œéƒ½ç¡®ä¿ PDF å¸¸ç”¨åŒ…åˆ°ä½ï¼ˆå·²è£…åˆ™è·³è¿‡ï¼‰
      run_with_retry "å®‰è£…åç«¯ PDF ä¾èµ–" 900 2 uv pip install pdfplumber pdfminer.six pymupdf pillow pytesseract
    )
    ok "åç«¯ä¾èµ–å®‰è£…å®Œæˆ"
  fi
}

action_install_pdf_env() {
  apply_session_mirrors_and_proxy
  install_pdf_runtime
  # åç«¯è™šæ‹Ÿç¯å¢ƒçš„ Python ä¾èµ–ä¹Ÿé¡ºæ‰‹ç¡®ä¿ä¸€ä¸‹
  if [[ -d apps/backend ]]; then
    (
      cd apps/backend
      [[ -d .venv ]] || uv venv
      source .venv/bin/activate
      run_with_retry "å®‰è£…åç«¯ PDF ä¾èµ–" 900 2 uv pip install pdfplumber pdfminer.six pymupdf pillow pytesseract
    )
  fi
  ok "ğŸ‰ PDF è§£æç¯å¢ƒå·²å°±ç»ª"
}

create_envs_if_needed() {
  local changed=false

  if [[ -f .env.example && ! -f .env ]]; then
    cp .env.example .env
    ok "å·²ä» .env.example ç”Ÿæˆ .env"
    changed=true
  fi

  if [[ -d apps/backend ]]; then
    if [[ -f apps/backend/.env.sample && ! -f apps/backend/.env ]]; then
      cp apps/backend/.env.sample apps/backend/.env
      ok "åç«¯ .env å·²ç”Ÿæˆ"
      changed=true
    fi
  fi

  if [[ -d apps/frontend ]]; then
    if [[ -f apps/frontend/.env.sample && ! -f apps/frontend/.env ]]; then
      cp apps/frontend/.env.sample apps/frontend/.env
      ok "å‰ç«¯ .env å·²ç”Ÿæˆ"
      changed=true
    fi
  fi

  # å³ä½¿æ²¡æœ‰ä»»ä½•æ–‡ä»¶å¯å¤åˆ¶ï¼Œä¹Ÿä¸ç®—å¤±è´¥
  return 0
}

# ========================= Git / Compose =========================
git_pull_if_repo() {
  if [[ -d .git ]]; then
    info "æ£€æµ‹åˆ° Git ä»“åº“ï¼Œgit pull..."
    git fetch --all --prune
    git pull --rebase --autostash || { err "git pull å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨è§£å†³å†²çªåé‡è¯•"; return 1; }
    ok "ä»£ç å·²æ›´æ–°"
  else
    info "é git ç›®å½•ï¼Œè·³è¿‡æ›´æ–°ä»£ç "
  fi
}

has_compose() { [[ -f docker-compose.yml || -f compose.yml ]]; }

compose_up() {
  if have docker && (have docker-compose || have docker compose); then
    local cmd=(docker compose)
    have docker-compose && cmd=(docker-compose)
    run_with_retry "compose build+up -d" 1200 1 "${cmd[@]}" up -d --build
  else
    err "æœªå®‰è£… docker / docker compose"
    return 1
  fi
}

compose_down() {
  if have docker && (have docker-compose || have docker compose); then
    local cmd=(docker compose)
    have docker-compose && cmd=(docker-compose)
    "${cmd[@]}" down || true
  fi
}

# ========================= PM2ï¼ˆæŒä¹…åŒ–ï¼‰ =========================
ensure_pm2() {
  if ! have pm2; then
    info "å®‰è£… pm2..."
    run_with_retry "npm i -g pm2" 600 1 npm i -g pm2
  fi
  ok "pm2 å°±ç»ªï¼š$(pm2 -v)"
}

pm2_write_ecosystem() {
  cat > ecosystem.config.js <<'EOF'
module.exports = {
  apps: [
    {
      name: "resume-backend",
      cwd: "apps/backend",
      script: "uv",
      args: "run uvicorn app.main:app --host 0.0.0.0 --port 8000",
      interpreter: null,
      instances: 1,                  // SQLite å•è¿›ç¨‹å†™
      exec_mode: "fork",
      autorestart: true,
      max_memory_restart: "512M",
      env: {
        "PYTHONUNBUFFERED": "1",
        "UV_HTTP_TIMEOUT": "120"
      }
    },
    {
      name: "resume-frontend",
      cwd: "apps/frontend",
      script: "npm",
      args: "start",
      interpreter: null,
      instances: 1,
      exec_mode: "fork",
      autorestart: true,
      max_memory_restart: "512M",
      env: {
        "NODE_ENV": "production",
        "PORT": "3000"
      }
    }
  ]
}
EOF
  ok "å·²ç”Ÿæˆ ecosystem.config.js"
}

pm2_start_and_persist() {
  ensure_pm2
  [[ -f ecosystem.config.js ]] || pm2_write_ecosystem
  info "ä½¿ç”¨ PM2 å¯åŠ¨æˆ–é‡å¯åº”ç”¨..."
  pm2 start ecosystem.config.js || pm2 restart all
  pm2 save
  # å¼€æœºè‡ªå¯ï¼ˆå°½é‡è‡ªåŠ¨æ‰§è¡Œï¼›è‹¥éœ€è¦ sudoï¼Œå°†å°è¯•è°ƒç”¨ï¼‰
  if have sudo; then
    sudo pm2 startup -u "$USER" --hp "$HOME" >/dev/null 2>&1 || pm2 startup >/dev/null 2>&1 || true
  else
    pm2 startup >/dev/null 2>&1 || true
  fi
  ok "PM2 å·²æŒä¹…åŒ–ï¼ˆå´©æºƒ/é‡å¯è‡ªåŠ¨æ‹‰èµ·ï¼‰"
}

# ========================= å¯åœ / æ—¥å¿— / çŠ¶æ€ =========================
pid_file_dev="$RUNTIME_DIR/${APP_NAME}_dev.pid"
log_dev="$RUNTIME_DIR/${APP_NAME}_dev.log"

detect_scripts() {
  HAS_NPM_DEV=false; HAS_NPM_START=false; HAS_NPM_BUILD=false
  if [[ -f package.json ]]; then
    local pkg; pkg="$(cat package.json)"
    grep -q '"dev"\s*:'   <<<"$pkg" && HAS_NPM_DEV=true
    grep -q '"start"\s*:' <<<"$pkg" && HAS_NPM_START=true
    grep -q '"build"\s*:' <<<"$pkg" && HAS_NPM_BUILD=true
  fi
}

action_install() {
  apply_session_mirrors_and_proxy || { err "apply_session_mirrors_and_proxy å¤±è´¥"; return 1; }

  echo "[STEP] auto_fix_deps"
  auto_fix_deps || { err "auto_fix_deps å¤±è´¥"; return 1; }

  echo "[STEP] install_or_update_uv"
  install_or_update_uv || { err "install_or_update_uv å¤±è´¥"; return 1; }

  echo "[STEP] create_envs_if_needed"
  create_envs_if_needed || { err "create_envs_if_needed å¤±è´¥"; return 1; }

  echo "[STEP] install_root_node"
  install_root_node || { err "install_root_node å¤±è´¥"; return 1; }

  echo "[STEP] install_backend_py"
  install_backend_py || { err "install_backend_py å¤±è´¥"; return 1; }

  echo "[STEP] install_frontend_node"
  install_frontend_node || { err "install_frontend_node å¤±è´¥"; return 1; }

  echo "[STEP] install_pdf_env"
  action_install_pdf_env || { err "install_pdf_env å¤±è´¥"; return 1; }

  ok "ğŸ‰ å®‰è£…/åˆå§‹åŒ–å®Œæˆ"
}

action_update() {
  apply_session_mirrors_and_proxy
  git_pull_if_repo
  action_install
}

action_build_root() {
  apply_session_mirrors_and_proxy
  if [[ -f package.json ]]; then
    info "å¼€å§‹æ„å»ºï¼ˆrootï¼šnpm run buildï¼‰..."
    if [[ ! -d node_modules ]]; then
      if [[ -f package-lock.json ]]; then
        run_with_retry "npm ci (root)" 600 2 npm ci --no-fund --no-audit --ignore-scripts
      else
        run_with_retry "npm install (root)" 900 2 npm install --no-fund --no-audit --ignore-scripts
      fi
    fi
    if grep -q '"build"\s*:' package.json; then
      run_with_retry "npm run build (root)" 1200 1 bash -lc "CI=1 NEXT_TELEMETRY_DISABLED=1 npm run build </dev/null"
      ok "æ„å»ºå®Œæˆï¼šroot"
    else
      err "package.json æœªå®šä¹‰ build è„šæœ¬"
      return 1
    fi
  else
    err "æœªæ‰¾åˆ° package.json"
    return 1
  fi
}

action_start_dev() {
  apply_session_mirrors_and_proxy
  detect_scripts
  if [[ "$HAS_NPM_DEV" == true ]]; then
    info "ä»¥ npm run dev å¯åŠ¨ï¼ˆæ—¥å¿—ï¼š$log_devï¼‰"
    nohup bash -lc "npm run dev" >"$log_dev" 2>&1 &
    echo $! >"$pid_file_dev"
    ok "å¼€å‘æœåŠ¡å·²å¯åŠ¨ (PID $(cat "$pid_file_dev"))"
  else
    err "æœªæ£€æµ‹åˆ°æ ¹ç›®å½•çš„ npm run devï¼›è¯·åˆ°å…·ä½“å­é¡¹ç›®æ‰‹åŠ¨å¯åŠ¨æˆ–æ·»åŠ  dev è„šæœ¬"
    return 1
  fi
}

action_start_prod() {
  apply_session_mirrors_and_proxy
  detect_scripts
  if has_compose; then
    info "æ£€æµ‹åˆ° docker composeï¼Œåå°å¯åŠ¨..."
    compose_up
    ok "ç”Ÿäº§æœåŠ¡å·²é€šè¿‡ compose å¯åŠ¨"
  elif [[ "$HAS_NPM_BUILD" == true || "$HAS_NPM_START" == true ]]; then
    info "ä½¿ç”¨ npm æ„å»ºç”Ÿäº§åŒ…..."
    [[ "$HAS_NPM_BUILD" == true ]] && run_with_retry "npm run build (prod)" 1200 1 bash -lc "CI=1 NEXT_TELEMETRY_DISABLED=1 npm run build </dev/null" || true
    info "åˆ‡æ¢ä¸º PM2 æŒä¹…åŒ–è¿è¡Œ..."
    pm2_start_and_persist
  else
    err "æœªæ£€æµ‹åˆ° compose æˆ– start/build è„šæœ¬ï¼Œæ— æ³•è‡ªåŠ¨å¯åŠ¨ç”Ÿäº§æœåŠ¡"
    return 1
  fi
}

action_stop() {
  local stopped=false
  # åœ nohup è¿›ç¨‹ï¼ˆæ—§æ–¹å¼ï¼‰
  if [[ -f "$pid_file_dev" ]]; then
    local pid; pid="$(cat "$pid_file_dev")"
    if ps -p "$pid" >/dev/null 2>&1; then
      kill "$pid" || true
      stopped=true
      ok "å·²åœæ­¢å¼€å‘è¿›ç¨‹ PID $pid"
    fi
    rm -f "$pid_file_dev"
  fi
  if [[ -f "$RUNTIME_DIR/${APP_NAME}_prod.pid" ]]; then
    local p; p="$(cat "$RUNTIME_DIR/${APP_NAME}_prod.pid")"
    if ps -p "$p" >/dev/null 2>&1; then
      kill "$p" || true
      stopped=true
      ok "å·²åœæ­¢ç”Ÿäº§è¿›ç¨‹ PID $p"
    fi
    rm -f "$RUNTIME_DIR/${APP_NAME}_prod.pid"
  fi
  # åœ PM2
  if have pm2; then
    pm2 stop resume-backend  >/dev/null 2>&1 || true
    pm2 stop resume-frontend >/dev/null 2>&1 || true
    stopped=true
    ok "PM2 è¿›ç¨‹å·²åœæ­¢ï¼ˆresume-backend / resume-frontendï¼‰"
  fi
  # åœ compose
  if has_compose && (have docker-compose || have docker compose); then
    info "åœæ­¢ compose æœåŠ¡..."
    compose_down
    stopped=true
    ok "compose æœåŠ¡å·²åœæ­¢"
  fi
  $stopped || info "æœªå‘ç°è¿è¡Œä¸­çš„æœ¬è„šæœ¬ç®¡ç†çš„è¿›ç¨‹"
}

action_status() {
  echo "---- çŠ¶æ€ ----"
  if have pm2; then
    pm2 status || true
  else
    echo "(PM2 æœªå®‰è£…)"
  fi
  if [[ -f "$pid_file_dev" ]]; then
    pid="$(cat "$pid_file_dev")"
    if ps -p "$pid" >/dev/null 2>&1; then
      echo "å¼€å‘ï¼šè¿è¡Œä¸­ (PID $pid)"
    else
      echo "å¼€å‘ï¼šè®°å½•å­˜åœ¨ä½†è¿›ç¨‹æœªè¿è¡Œ"
    fi
  else
    echo "å¼€å‘ï¼šæœªå¯åŠ¨"
  fi
  if [[ -f "$RUNTIME_DIR/${APP_NAME}_prod.pid" ]]; then
    p="$(cat "$RUNTIME_DIR/${APP_NAME}_prod.pid")"
    if ps -p "$p" >/dev/null 2>&1; then
      echo "ç”Ÿäº§ï¼šè¿è¡Œä¸­ (PID $p)"
    else
      echo "ç”Ÿäº§ï¼šè®°å½•å­˜åœ¨ä½†è¿›ç¨‹æœªè¿è¡Œ"
    fi
  else
    if has_compose && have docker; then
      echo "ç”Ÿäº§ï¼ˆcomposeï¼‰ï¼š"
      if have docker-compose; then docker-compose ps || true; else docker compose ps || true; fi
    else
      echo "ç”Ÿäº§ï¼šç”± PM2 æ‰˜ç®¡ï¼ˆè§ä¸Šè¡¨ï¼‰æˆ–æœªå¯åŠ¨"
    fi
  fi
}

action_logs() {
  echo "---- æ—¥å¿— ----"
  if have pm2; then
    echo "[PM2] æŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼š pm2 logs"
    pm2 logs --lines 50 || true
  else
    echo "(PM2 æœªå®‰è£…ï¼Œå±•ç¤º nohup/compose æ—¥å¿—)"
    [[ -f "$log_dev" ]] && echo "[dev] $log_dev:" && tail -n 50 "$log_dev" || echo "æš‚æ— å¼€å‘æ—¥å¿—"
    if [[ -f "$RUNTIME_DIR/${APP_NAME}_prod.log" ]]; then
      echo "[prod] $RUNTIME_DIR/${APP_NAME}_prod.log:"
      tail -n 50 "$RUNTIME_DIR/${APP_NAME}_prod.log"
    elif has_compose && have docker; then
      echo "[compose] æœ€è¿‘ 100 è¡Œï¼š"
      if have docker-compose; then docker-compose logs --tail=100 || true; else docker compose logs --tail=100 || true; fi
    else
      echo "æš‚æ— ç”Ÿäº§æ—¥å¿—"
    fi
  fi
}

action_uninstall() {
  read -r -p "æ­¤æ“ä½œä¼šåˆ é™¤ node_modulesã€.venvã€æ„å»ºäº§ç‰©ä¸è¿è¡Œæ—¶æ–‡ä»¶ï¼Œç»§ç»­ï¼Ÿ(y/N) " yn
  case "$yn" in
    [Yy]*)
      info "å¼€å§‹æ¸…ç†..."
      # åœ PM2
      if have pm2; then
        pm2 delete resume-backend  >/dev/null 2>&1 || true
        pm2 delete resume-frontend >/dev/null 2>&1 || true
        pm2 save >/dev/null 2>&1 || true
      fi
      rm -rf node_modules package-lock.json "$RUNTIME_DIR" ecosystem.config.js
      [[ -d apps/frontend ]] && (cd apps/frontend && rm -rf node_modules package-lock.json dist .next)
      [[ -d apps/backend  ]] && (cd apps/backend  && rm -rf .venv __pycache__)
      if has_compose && have docker; then
        info "æ¸…ç† compose å®¹å™¨/ç½‘ç»œï¼ˆå¦‚å­˜åœ¨ï¼‰..."
        if have docker-compose; then docker-compose down -v || true; else docker compose down -v || true; fi
      fi
      ok "æ¸…ç†å®Œæˆ"
      ;;
    *) info "å·²å–æ¶ˆ";;
  esac
}

action_set_mirrors() {
  echo "å½“å‰é•œåƒï¼š"
  echo "  1) npmï¼š$NPM_REGISTRY_DEFAULT"
  echo "  2) pipï¼š$PIP_INDEX_DEFAULT"
  read -r -p "è¾“å…¥æ–°çš„ npm é•œåƒï¼ˆç•™ç©ºä¸å˜ï¼‰ï¼š" nmr
  read -r -p "è¾“å…¥æ–°çš„ pip é•œåƒï¼ˆç•™ç©ºä¸å˜ï¼‰ï¼š" pmi
  [[ -n "${nmr:-}" ]] && NPM_REGISTRY_DEFAULT="$nmr"
  [[ -n "${pmi:-}" ]] && PIP_INDEX_DEFAULT="$pmi" && UV_INDEX_DEFAULT="$pmi"
  read -r -p "æ˜¯å¦æŒä¹…åŒ–åˆ°æœ¬æœºé…ç½®ï¼ˆnpm config / ~/.pip/pip.confï¼‰ï¼Ÿ(y/N) " yn
  if [[ "$yn" =~ ^[Yy]$ ]]; then
    npm config set registry "$NPM_REGISTRY_DEFAULT"
    mkdir -p "$HOME/.pip"
    cat >"$HOME/.pip/pip.conf" <<EOF
[global]
index-url = ${PIP_INDEX_DEFAULT}
EOF
    ok "é•œåƒå·²æŒä¹…åŒ–"
  fi
  persist_conf
}

action_set_proxy() {
  echo "å½“å‰ä»£ç†ï¼šHTTP=${HTTP_PROXY_DEFAULT:-none}  HTTPS=${HTTPS_PROXY_DEFAULT:-none}"
  read -r -p "è®¾ç½® HTTP ä»£ç†ï¼ˆä¾‹ï¼šhttp://127.0.0.1:7890ï¼Œç•™ç©ºæ¸…ç©ºï¼‰ï¼š" hp
  read -r -p "è®¾ç½® HTTPS ä»£ç†ï¼ˆä¾‹ï¼šhttp://127.0.0.1:7890ï¼Œç•™ç©ºæ¸…ç©ºï¼‰ï¼š" hsp
  HTTP_PROXY_DEFAULT="${hp:-}"
  HTTPS_PROXY_DEFAULT="${hsp:-}"
  persist_conf
  ok "ä»£ç†å·²æ›´æ–°ï¼ˆæ‰§è¡ŒåŠ¨ä½œæ—¶è‡ªåŠ¨ç”Ÿæ•ˆï¼‰"
}

press_enter() { read -r -p "æŒ‰å›è½¦é”®è¿”å›èœå•..." _; }

# ========================= èœå•å¾ªç¯ =========================
while true; do
  clear
  echo "=========== $APP_NAME ä¸€é”®éƒ¨ç½² ==========="
  echo "1) å®‰è£…/åˆå§‹åŒ–"
  echo "2) æ›´æ–°"
  echo "3) ä»…æ„å»ºï¼ˆæ ¹ç›®å½• npm run buildï¼‰"
  echo "4) å¯åŠ¨ï¼ˆå¼€å‘æ¨¡å¼ï¼‰"
  echo "5) å¯åŠ¨ï¼ˆç”Ÿäº§æ¨¡å¼ï¼‰"
  echo "6) åœæ­¢ï¼ˆå¼€å‘/ç”Ÿäº§/PM2/composeï¼‰"
  echo "7) æŸ¥çœ‹çŠ¶æ€"
  echo "8) æŸ¥çœ‹æ—¥å¿—ï¼ˆä¼˜å…ˆPM2ï¼‰"
  echo "9) å¸è½½/æ¸…ç†"
  echo "10) é•œåƒè®¾ç½®ï¼ˆnpm/pipï¼Œæ”¯æŒæŒä¹…åŒ–ï¼‰"
  echo "11) ä»£ç†è®¾ç½®ï¼ˆHTTP/HTTPSï¼‰"
  echo "12) å®‰è£…PDFè§£æç¯å¢ƒ"
  echo "13) é€€å‡º"
  echo "========================================="
  read -r -p "è¯·è¾“å…¥é€‰é¡¹ç¼–å·ï¼š " choice
  case "$choice" in
    1)  action_install;         press_enter;;
    2)  action_update;          press_enter;;
    3)  action_build_root;      press_enter;;
    4)  action_start_dev;       press_enter;;
    5)  action_start_prod;      press_enter;;
    6)  action_stop;            press_enter;;
    7)  action_status;          press_enter;;
    8)  action_logs;            press_enter;;
    9)  action_uninstall;       press_enter;;
    10) action_set_mirrors;     press_enter;;
    11) action_set_proxy;       press_enter;;
    12) action_install_pdf_env; press_enter;;
    13) echo "Bye~"; exit 0;;
    *) echo "æ— æ•ˆé€‰é¡¹"; sleep 1;;
  esac
done
